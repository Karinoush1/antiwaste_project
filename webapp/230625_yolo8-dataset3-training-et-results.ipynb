{"cells":[{"cell_type":"markdown","metadata":{"id":"bRRhWEc-ZsFj"},"source":["# Préparation dataset"]},{"cell_type":"markdown","metadata":{"id":"z7HWgYi1aOqa"},"source":["On crée d'abord un répertoire data pour y ranger nos datasets."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:36:40.048154Z","iopub.status.busy":"2023-06-25T01:36:40.047412Z","iopub.status.idle":"2023-06-25T01:36:40.416425Z","shell.execute_reply":"2023-06-25T01:36:40.415296Z","shell.execute_reply.started":"2023-06-25T01:36:40.048126Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"Add Tag\")\n","secret_value_1 = user_secrets.get_secret(\"Secret Key\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:03:20.521142Z","iopub.status.busy":"2023-06-25T06:03:20.520550Z","iopub.status.idle":"2023-06-25T06:03:21.329630Z","shell.execute_reply":"2023-06-25T06:03:21.328620Z","shell.execute_reply.started":"2023-06-25T06:03:20.521112Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687434632266,"user":{"displayName":"fred971","userId":"09901168721795634717"},"user_tz":240},"id":"EVevvMkkZrXo","outputId":"b398362d-684e-4974-f210-09de922bd9f6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove '/kaggle/working/data': No such file or directory\n","rm: cannot remove '/kaggle/working/Fruitsflow/': No such file or directory\n","/kaggle/working/data\n"]}],"source":["!rm -r /kaggle/working/data\n","!rm -r /kaggle/working/Fruitsflow/\n","!mkdir /kaggle/working/data\n","%cd /kaggle/working/data"]},{"cell_type":"markdown","metadata":{"id":"gN-mg7u3agYz"},"source":["Je me suis placé dans le répertoire data. Je peux y cloner le repo du dataset fruits360."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:03:25.583041Z","iopub.status.busy":"2023-06-25T06:03:25.582202Z","iopub.status.idle":"2023-06-25T06:04:22.232657Z","shell.execute_reply":"2023-06-25T06:04:22.231512Z","shell.execute_reply.started":"2023-06-25T06:03:25.583008Z"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1687434632527,"user":{"displayName":"fred971","userId":"09901168721795634717"},"user_tz":240},"id":"7BjQwSdFZ3Dg","outputId":"3d5573e9-5f8e-4e25-e499-bffaa123a482","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Fruitsflow'...\n","remote: Enumerating objects: 50153, done.\u001b[K\n","remote: Total 50153 (delta 0), reused 0 (delta 0), pack-reused 50153\u001b[K\n","Receiving objects: 100% (50153/50153), 1.42 GiB | 27.51 MiB/s, done.\n","Resolving deltas: 100% (7435/7435), done.\n","Updating files: 100% (35103/35103), done.\n"]}],"source":["!git clone https://github.com/971FLS/Fruitsflow"]},{"cell_type":"markdown","metadata":{"id":"lh46byMPakT5"},"source":["Je rentre d'abord l'arborescence jusqu'à atteindre les répertoires Test et Training. Puis, je peux uploader des photos à prédire plus tard."]},{"cell_type":"markdown","metadata":{"id":"Dq8rfHbcau5x"},"source":["Notre dataset est prêt. Nous avons même de quoi ranger des éventuels datasets complémentaires."]},{"cell_type":"markdown","metadata":{"id":"XjnnWhGGa2zm"},"source":["# Installation YOLO v8"]},{"cell_type":"markdown","metadata":{"id":"gOcIMw-Xa7DU"},"source":["Suivi du process indiqué ici : [Ultralytics](https://docs.ultralytics.com/quickstart/#install)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:37:26.219976Z","iopub.status.busy":"2023-06-25T01:37:26.219618Z","iopub.status.idle":"2023-06-25T01:37:26.227773Z","shell.execute_reply":"2023-06-25T01:37:26.226648Z","shell.execute_reply.started":"2023-06-25T01:37:26.219945Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687434632528,"user":{"displayName":"fred971","userId":"09901168721795634717"},"user_tz":240},"id":"T5YD3G_AfA6q","outputId":"2a1b2f25-b365-403d-828c-576f213830cd","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n"]}],"source":["%cd /kaggle/working/"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:37:26.230257Z","iopub.status.busy":"2023-06-25T01:37:26.229352Z","iopub.status.idle":"2023-06-25T01:37:26.239694Z","shell.execute_reply":"2023-06-25T01:37:26.238298Z","shell.execute_reply.started":"2023-06-25T01:37:26.230232Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687434632528,"user":{"displayName":"fred971","userId":"09901168721795634717"},"user_tz":240},"id":"gxRHRwzwg-ui","trusted":true},"outputs":[],"source":["# Dependency ultralytics<=8.0.20 is required but found version=8.0.117, to fix: `pip install ultralytics<=8.0.20`\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:37:26.241590Z","iopub.status.busy":"2023-06-25T01:37:26.241150Z","iopub.status.idle":"2023-06-25T01:37:40.874160Z","shell.execute_reply":"2023-06-25T01:37:40.872845Z","shell.execute_reply.started":"2023-06-25T01:37:26.241559Z"},"executionInfo":{"elapsed":7591,"status":"ok","timestamp":1687434640116,"user":{"displayName":"fred971","userId":"09901168721795634717"},"user_tz":240},"id":"tz5LE85iaNbw","outputId":"e0332228-3e60-46e8-8241-4303549428c7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ultralytics\n","  Downloading ultralytics-8.0.122-py3-none-any.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.0/612.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.6.3)\n","Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.4.1)\n","Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.28.2)\n","Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\n","Requirement already satisfied: torchvision>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\n","Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n","Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (21.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","Installing collected packages: ultralytics\n","Successfully installed ultralytics-8.0.122\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install ultralytics\n","#!pip install ultralytics<=8.0.20 # Erreur : /bin/bash: =8.0.20: No such file or directory\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:37:40.877469Z","iopub.status.busy":"2023-06-25T01:37:40.877057Z","iopub.status.idle":"2023-06-25T01:37:52.007508Z","shell.execute_reply":"2023-06-25T01:37:52.006278Z","shell.execute_reply.started":"2023-06-25T01:37:40.877428Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.7.0.72)\n","Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:37:52.011002Z","iopub.status.busy":"2023-06-25T01:37:52.009792Z","iopub.status.idle":"2023-06-25T01:38:03.266507Z","shell.execute_reply":"2023-06-25T01:38:03.265334Z","shell.execute_reply.started":"2023-06-25T01:37:52.010957Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install pillow"]},{"cell_type":"markdown","metadata":{"id":"-kO26DpNKamS"},"source":["# Téléchargement du dataset\n","Dataset : https://public.roboflow.com/object-detection/synthetic-fruit/1"]},{"cell_type":"markdown","metadata":{"id":"SLAKIAYqbflU"},"source":["# Entrainement du modèle"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:38:03.268959Z","iopub.status.busy":"2023-06-25T01:38:03.268545Z","iopub.status.idle":"2023-06-25T01:38:03.275479Z","shell.execute_reply":"2023-06-25T01:38:03.274536Z","shell.execute_reply.started":"2023-06-25T01:38:03.268920Z"},"trusted":true},"outputs":[],"source":["url = '/kaggle/working/'"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T01:38:03.278887Z","iopub.status.busy":"2023-06-25T01:38:03.278441Z","iopub.status.idle":"2023-06-25T05:36:28.668242Z","shell.execute_reply":"2023-06-25T05:36:28.666592Z","shell.execute_reply.started":"2023-06-25T01:38:03.278853Z"},"id":"0V8MmbyZbVpL","outputId":"3b568973-0910-449a-cba0-4a1475267ce9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n","YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n","\n","Ultralytics YOLOv8.0.122 🚀 Python-3.10.10 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/kaggle/working/data/Fruitsflow/dataset/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100%|██████████| 755k/755k [00:00<00:00, 16.5MB/s]\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","Overriding model.yaml nc=80 with nc=131\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1   1426891  ultralytics.nn.modules.head.Detect           [131, [64, 128, 256]]         \n","YOLOv8n summary: 225 layers, 3686427 parameters, 3686411 gradients\n","\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230625_014028-v3qs0xhb</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/frederic-lopes/YOLOv8/runs/v3qs0xhb' target=\"_blank\">silvery-spaceship-17</a></strong> to <a href='https://wandb.ai/frederic-lopes/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/frederic-lopes/YOLOv8' target=\"_blank\">https://wandb.ai/frederic-lopes/YOLOv8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/frederic-lopes/YOLOv8/runs/v3qs0xhb' target=\"_blank\">https://wandb.ai/frederic-lopes/YOLOv8/runs/v3qs0xhb</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n","100%|██████████| 6.23M/6.23M [00:00<00:00, 70.6MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/Fruitsflow/dataset/train/labels... 12285 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12285/12285 [00:08<00:00, 1387.39it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/Fruitsflow/dataset/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/Fruitsflow/dataset/val/labels... 1755 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1755/1755 [00:01<00:00, 1008.90it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/Fruitsflow/dataset/val/labels.cache\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 1 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50      2.88G      1.641      2.029      2.086         38        640: 100%|██████████| 768/768 [04:32<00:00,  2.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:23<00:00,  2.35it/s]\n","                   all       1755       2912      0.662      0.628      0.678      0.512\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50      2.89G     0.8592     0.9038      1.372         29        640: 100%|██████████| 768/768 [04:26<00:00,  2.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.47it/s]\n","                   all       1755       2912      0.972      0.931      0.981       0.82\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50      2.89G     0.6606     0.6724      1.163         38        640: 100%|██████████| 768/768 [04:21<00:00,  2.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.50it/s]\n","                   all       1755       2912      0.981      0.972      0.984      0.883\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50      2.84G     0.5611     0.5582      1.069         37        640: 100%|██████████| 768/768 [04:19<00:00,  2.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.49it/s]\n","                   all       1755       2912      0.987      0.972      0.991      0.915\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/50      2.89G     0.5064     0.5008      1.024         30        640: 100%|██████████| 768/768 [04:17<00:00,  2.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.44it/s]\n","                   all       1755       2912      0.979      0.981      0.993      0.935\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/50      2.89G     0.4744     0.4672     0.9981         38        640: 100%|██████████| 768/768 [04:18<00:00,  2.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.42it/s]\n","                   all       1755       2912      0.993      0.985      0.994      0.936\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/50      2.84G     0.4459     0.4404     0.9779         39        640: 100%|██████████| 768/768 [04:17<00:00,  2.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.43it/s]\n","                   all       1755       2912      0.991      0.992      0.994      0.944\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/50      2.89G     0.4251     0.4206      0.967         30        640: 100%|██████████| 768/768 [04:18<00:00,  2.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.42it/s]\n","                   all       1755       2912      0.994      0.986      0.995      0.966\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/50      2.89G     0.4024        0.4     0.9526         29        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.52it/s]\n","                   all       1755       2912      0.996      0.992      0.994      0.965\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/50      2.89G     0.3857     0.3835     0.9416         29        640: 100%|██████████| 768/768 [04:15<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.994       0.99      0.994      0.975\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/50      2.89G     0.3732     0.3693     0.9339         28        640: 100%|██████████| 768/768 [04:16<00:00,  2.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.995      0.993      0.995       0.98\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/50      2.89G     0.3621     0.3577     0.9252         20        640: 100%|██████████| 768/768 [04:16<00:00,  2.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.995      0.993      0.995      0.982\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/50      2.89G     0.3491     0.3432     0.9185         32        640: 100%|██████████| 768/768 [04:15<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.52it/s]\n","                   all       1755       2912      0.996      0.993      0.995      0.986\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/50      2.89G     0.3349     0.3334       0.91         32        640: 100%|██████████| 768/768 [04:15<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.50it/s]\n","                   all       1755       2912      0.995      0.995      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/50      2.89G     0.3278     0.3266     0.9068         37        640: 100%|██████████| 768/768 [04:15<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.44it/s]\n","                   all       1755       2912      0.997      0.994      0.995      0.989\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/50      2.89G     0.3171     0.3153     0.9003         25        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.998      0.992      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/50      2.89G     0.3111       0.31     0.8974         37        640: 100%|██████████| 768/768 [04:15<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.43it/s]\n","                   all       1755       2912      0.995      0.995      0.995      0.989\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/50      2.89G     0.3048     0.3017     0.8939         27        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.52it/s]\n","                   all       1755       2912      0.999      0.994      0.995       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/50      2.89G     0.3024     0.3012     0.8942         32        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.43it/s]\n","                   all       1755       2912      0.997      0.996      0.995       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/50      2.89G     0.2903      0.289     0.8883         22        640: 100%|██████████| 768/768 [04:16<00:00,  2.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.998      0.995      0.995       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/50      2.89G     0.2834     0.2826     0.8847         34        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.44it/s]\n","                   all       1755       2912      0.998      0.995      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/50      2.84G      0.282      0.281     0.8836         33        640: 100%|██████████| 768/768 [04:17<00:00,  2.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.999      0.994      0.995      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/50      2.89G      0.276      0.277     0.8801         32        640: 100%|██████████| 768/768 [04:17<00:00,  2.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.50it/s]\n","                   all       1755       2912      0.998      0.994      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/50      2.89G     0.2731     0.2717     0.8785         40        640: 100%|██████████| 768/768 [04:15<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.999      0.995      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/50      2.89G     0.2649     0.2665     0.8769         33        640: 100%|██████████| 768/768 [04:15<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.998      0.994      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/50      2.89G     0.2636     0.2625     0.8738         41        640: 100%|██████████| 768/768 [04:15<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.997      0.996      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/50      2.89G     0.2586     0.2591      0.872         30        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.52it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/50      2.89G     0.2544     0.2549     0.8707         46        640: 100%|██████████| 768/768 [04:14<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.44it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/50      2.84G     0.2512     0.2521     0.8685         27        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.997      0.997      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/50      2.89G     0.2468     0.2492     0.8676         36        640: 100%|██████████| 768/768 [04:14<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/50      2.89G     0.2437     0.2468     0.8665         34        640: 100%|██████████| 768/768 [04:15<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.53it/s]\n","                   all       1755       2912      0.998      0.997      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/50      2.89G     0.2401     0.2424     0.8655         37        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.998      0.997      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/50      2.89G     0.2376     0.2388     0.8628         43        640: 100%|██████████| 768/768 [04:13<00:00,  3.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.47it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/50      2.89G     0.2357     0.2389     0.8628         27        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.999      0.997      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/50      2.89G     0.2321     0.2349     0.8617         36        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.53it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/50      2.89G     0.2277     0.2324     0.8594         41        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/50      2.89G     0.2264      0.231      0.858         27        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.999      0.997      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/50      2.89G     0.2253     0.2282     0.8582         29        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.50it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/50      2.89G     0.2249     0.2293     0.8589         29        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.43it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/50      2.89G     0.2201      0.226      0.855         35        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/50      2.89G     0.2219     0.2264     0.8566         23        640: 100%|██████████| 768/768 [04:13<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.45it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/50      2.89G     0.2182      0.224     0.8566         41        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:21<00:00,  2.53it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/50      2.89G     0.2169     0.2226     0.8533         28        640: 100%|██████████| 768/768 [04:17<00:00,  2.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/50      2.89G      0.218     0.2234     0.8573         35        640: 100%|██████████| 768/768 [04:18<00:00,  2.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.43it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/50      2.89G     0.2168     0.2224     0.8558         25        640: 100%|██████████| 768/768 [04:18<00:00,  2.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/50      2.89G     0.2145     0.2196     0.8553         29        640: 100%|██████████| 768/768 [04:16<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.42it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      47/50      2.84G     0.2141     0.2208     0.8561         39        640: 100%|██████████| 768/768 [04:18<00:00,  2.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.47it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      48/50      2.84G     0.2135     0.2186     0.8535         34        640: 100%|██████████| 768/768 [04:17<00:00,  2.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      49/50      2.89G     0.2138     0.2195     0.8555         36        640: 100%|██████████| 768/768 [04:14<00:00,  3.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:22<00:00,  2.48it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      50/50      2.89G     0.2086     0.2164     0.8521         33        640: 100%|██████████| 768/768 [04:12<00:00,  3.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:25<00:00,  2.16it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","\n","50 epochs completed in 3.896 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 7.6MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 7.6MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.0.122 🚀 Python-3.10.10 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n","YOLOv8n summary (fused): 168 layers, 3680825 parameters, 0 gradients\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 55/55 [00:23<00:00,  2.31it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","        Apple Braeburn       1755       1755          1      0.998      0.995      0.994\n","                 Cocos       1755        119          1      0.994      0.995      0.993\n","                 Guava       1755        106      0.998          1      0.995      0.995\n","           Huckleberry       1755        127      0.999          1      0.995      0.995\n","                Papaya       1755        214          1      0.991      0.995      0.993\n","            Peach Flat       1755        122      0.999          1      0.995      0.994\n","          Pear Monster       1755        123      0.999          1      0.995      0.993\n","            Pear Stone       1755        117      0.999          1      0.995      0.993\n","            Redcurrant       1755        119      0.999          1      0.995      0.995\n","              Tomato 2       1755        110      0.997      0.982      0.995      0.993\n","Speed: 0.4ms preprocess, 2.7ms inference, 0.0ms loss, 1.5ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n","Ultralytics YOLOv8.0.122 🚀 Python-3.10.10 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n","YOLOv8n summary (fused): 168 layers, 3680825 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/Fruitsflow/dataset/val/labels.cache... 1755 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1755/1755 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 110/110 [00:25<00:00,  4.30it/s]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","        Apple Braeburn       1755       1755          1      0.998      0.995      0.994\n","                 Cocos       1755        119          1      0.994      0.995      0.993\n","                 Guava       1755        106      0.998          1      0.995      0.995\n","           Huckleberry       1755        127      0.998          1      0.995      0.995\n","                Papaya       1755        214          1      0.991      0.995      0.993\n","            Peach Flat       1755        122      0.999          1      0.995      0.994\n","          Pear Monster       1755        123      0.999          1      0.995      0.992\n","            Pear Stone       1755        117      0.999          1      0.995      0.991\n","            Redcurrant       1755        119      0.999          1      0.995      0.995\n","              Tomato 2       1755        110      0.997      0.982      0.995      0.992\n","Speed: 0.5ms preprocess, 4.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","\n","image 1/1 /kaggle/input/test2206/YOLOv8_multifruits1.jpg: 480x640 5 Apple Braeburns, 1 Huckleberry, 84.1ms\n","Speed: 4.5ms preprocess, 84.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","Ultralytics YOLOv8.0.122 🚀 Python-3.10.10 torch-2.0.0 CPU\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/detect/train/weights/best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 135, 8400) (7.2 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n"]},{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.24.3.dist-info/METADATA'\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.0s, saved as runs/detect/train/weights/best.onnx (12.7 MB)\n","\n","Export complete (1.5s)\n","Results saved to \u001b[1m/kaggle/working/runs/detect/train/weights\u001b[0m\n","Predict:         yolo predict task=detect model=runs/detect/train/weights/best.onnx imgsz=640 \n","Validate:        yolo val task=detect model=runs/detect/train/weights/best.onnx imgsz=640 data=/kaggle/working/data/Fruitsflow/dataset/data.yaml \n","Visualize:       https://netron.app\n"]},{"name":"stdout","output_type":"stream","text":["================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}],"source":["from ultralytics import YOLO\n","\n","# Create a new YOLO model from scratch\n","model = YOLO('yolov8n.yaml')\n","\n","# Load a pretrained YOLO model (recommended for training)\n","#model = YOLO('yolov8m.pt')\n","\n","# Train the model using the 'coco128.yaml' dataset for 3 epochs\n","results = model.train(data='/kaggle/working/data/Fruitsflow/dataset/data.yaml', epochs=50, imgsz=320, optimizer='Adam', lr0=0.0001, cos_lr=True)\n","\n","# Evaluate the model's performance on the validation set\n","results = model.val()\n","\n","# Perform object detection on an image using the model\n","results = model('/kaggle/input/test2206/YOLOv8_multifruits1.jpg')\n","\n","# Export the model to ONNX format\n","success = model.export(format='onnx')"]},{"cell_type":"markdown","metadata":{"id":"Wc00gTTcbxKZ"},"source":["## Evaluation du modèle (Val)\n","Doc : [https://docs.ultralytics.com/modes/val/](https://docs.ultralytics.com/modes/val/)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T05:36:28.671075Z","iopub.status.busy":"2023-06-25T05:36:28.670405Z","iopub.status.idle":"2023-06-25T05:37:02.537293Z","shell.execute_reply":"2023-06-25T05:37:02.536093Z","shell.execute_reply.started":"2023-06-25T05:36:28.671037Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ultralytics in /opt/conda/lib/python3.10/site-packages (8.0.122)\n","Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.6.3)\n","Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.4.1)\n","Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.28.2)\n","Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\n","Requirement already satisfied: torchvision>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\n","Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n","Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (21.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.7.0.72)\n","Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install ultralytics\n","!pip install opencv-python\n","!pip install pillow"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-25T01:15:10.246323Z","iopub.status.idle":"2023-06-25T01:15:10.246795Z","shell.execute_reply":"2023-06-25T01:15:10.246576Z","shell.execute_reply.started":"2023-06-25T01:15:10.246555Z"},"trusted":true},"outputs":[],"source":["url = \"/kaggle/working/\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:06:07.156920Z","iopub.status.busy":"2023-06-25T06:06:07.156483Z","iopub.status.idle":"2023-06-25T06:06:07.513610Z","shell.execute_reply":"2023-06-25T06:06:07.512537Z","shell.execute_reply.started":"2023-06-25T06:06:07.156893Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["python: can't open file '/kaggle/working/data/yolo': [Errno 2] No such file or directory\n"]}],"source":["!python yolo val task=detect model=/kaggle/input/besofl/best.pt imgsz=320 data=/kaggle/working/data/Fruitsflow/dataset/data.yaml"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:06:28.731324Z","iopub.status.busy":"2023-06-25T06:06:28.730971Z","iopub.status.idle":"2023-06-25T06:11:23.277180Z","shell.execute_reply":"2023-06-25T06:11:23.275533Z","shell.execute_reply.started":"2023-06-25T06:06:28.731297Z"},"id":"6k5BQop4b9Sd","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.122 🚀 Python-3.10.10 torch-2.0.0+cpu CPU\n","YOLOv8n summary (fused): 168 layers, 3680825 parameters, 0 gradients\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100%|██████████| 755k/755k [00:00<00:00, 25.6MB/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/Fruitsflow/dataset/val/labels... 1755 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1755/1755 [00:01<00:00, 1444.97it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/Fruitsflow/dataset/val/labels.cache\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 110/110 [04:46<00:00,  2.61s/it]\n","                   all       1755       2912      0.999      0.996      0.995      0.994\n","        Apple Braeburn       1755       1755          1      0.998      0.995      0.994\n","                 Cocos       1755        119          1      0.994      0.995      0.993\n","                 Guava       1755        106      0.998          1      0.995      0.995\n","           Huckleberry       1755        127      0.998          1      0.995      0.995\n","                Papaya       1755        214          1      0.991      0.995      0.993\n","            Peach Flat       1755        122      0.999          1      0.995      0.994\n","          Pear Monster       1755        123      0.999          1      0.995      0.992\n","            Pear Stone       1755        117      0.999          1      0.995      0.991\n","            Redcurrant       1755        119      0.999          1      0.995      0.995\n","              Tomato 2       1755        110      0.997      0.982      0.995      0.992\n","Speed: 2.9ms preprocess, 152.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n"]},{"data":{"text/plain":["array([    0.99402,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,\n","           0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99344,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,\n","           0.99359,     0.99359,     0.99359,     0.99359,     0.99496,     0.99359,     0.99485,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,\n","           0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99305,     0.99359,     0.99359,     0.99429,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99247,     0.99359,     0.99134,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,\n","           0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,       0.995,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,\n","           0.99359,     0.99245,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359,     0.99359])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Epoch 1 à 11h57\n","# Epoch 5 à 14h08\n","# Epoch 6 à 14h41\n","# Epoch 9 à 16h18\n","\n","from ultralytics import YOLO\n","\n","# Load a model\n","#model = YOLO('yolov8n.pt')  # load an official model\n","model = YOLO('/kaggle/input/besofl/best.pt')  # load a custom model\n","\n","\n","\n","# Validate the model\n","metrics = model.val()  # no arguments needed, dataset and settings remembered\n","metrics.box.map    # map50-95\n","metrics.box.map50  # map50\n","metrics.box.map75  # map75\n","metrics.box.maps   # a list contains map50-95 of each category"]},{"cell_type":"markdown","metadata":{"id":"lmybShhncJxn"},"source":["## Prédiction du modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-25T01:15:10.250320Z","iopub.status.idle":"2023-06-25T01:15:10.251112Z","shell.execute_reply":"2023-06-25T01:15:10.250899Z","shell.execute_reply.started":"2023-06-25T01:15:10.250877Z"},"id":"07UPDIjczj2M","trusted":true},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import cv2\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:17:00.562538Z","iopub.status.busy":"2023-06-25T06:17:00.562190Z","iopub.status.idle":"2023-06-25T06:17:00.945959Z","shell.execute_reply":"2023-06-25T06:17:00.944762Z","shell.execute_reply.started":"2023-06-25T06:17:00.562513Z"},"id":"dBZk-9FhcG_M","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"error","evalue":"OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:1255: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvNamedWindow'\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/test2206/YOLOv8_multifruits2.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_crop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:255\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m overrides \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m overrides:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mget_save_dir()\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:190\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:275\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[i]\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m()\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplotted_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplotted_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_preds(vid_cap, i, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m p\u001b[38;5;241m.\u001b[39mname))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:322\u001b[0m, in \u001b[0;36mBasePredictor.show\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinux\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m p \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m--> 322\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamedWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWINDOW_NORMAL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWINDOW_KEEPRATIO\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# allow window resize (Linux)\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mresizeWindow(\u001b[38;5;28mstr\u001b[39m(p), im0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], im0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    324\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;28mstr\u001b[39m(p), im0)\n","\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/highgui/src/window.cpp:1255: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvNamedWindow'\n"]}],"source":["model.predict('/kaggle/input/test2206/YOLOv8_multifruits2.jpg', save=True, imgsz=320, conf=0.5, show=True, save_conf=True, save_crop=True, boxes=True)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:28:18.397956Z","iopub.status.busy":"2023-06-25T06:28:18.397436Z","iopub.status.idle":"2023-06-25T06:28:27.652852Z","shell.execute_reply":"2023-06-25T06:28:27.650822Z","shell.execute_reply.started":"2023-06-25T06:28:18.397920Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ultralytics in /opt/conda/lib/python3.10/site-packages (8.0.122)\n","Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.6.3)\n","Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.4.1)\n","Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.28.2)\n","Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0+cpu)\n","Requirement already satisfied: torchvision>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1+cpu)\n","Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n","Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (21.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install ultralytics \n","from ultralytics import YOLO\n","\n","# Load a model\n","#model = YOLO('yolov8n.pt')  # load an official model\n","model = YOLO('/kaggle/input/besofl/best.pt')  # load a custom model\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:31:11.068337Z","iopub.status.busy":"2023-06-25T06:31:11.067981Z","iopub.status.idle":"2023-06-25T06:31:11.725596Z","shell.execute_reply":"2023-06-25T06:31:11.724272Z","shell.execute_reply.started":"2023-06-25T06:31:11.068314Z"},"id":"FSOGFCajmEVg","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","Downloading https://fr.wikipedia.org/wiki/Fichier:Avocado_Hass_-_single_and_halved.jpg to Fichier:Avocado_Hass_-_single_and_halved.jpg...\n","111kB [00:00, 9.35MB/s]\n"]},{"ename":"FileNotFoundError","evalue":"Image Not Found /kaggle/working/data/Fichier:Avocado_Hass_-_single_and_halved.jpg","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m img8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://upload.wikimedia.org/wikipedia/commons/thumb/8/86/L\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA9gumes_pour_ratatouille_au_march\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA9_d\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m27Apt.jpg/2560px-L\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA9gumes_pour_ratatouille_au_march\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA9_d\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m27Apt.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m img9 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://fr.wikipedia.org/wiki/Fichier:Avocado_Hass_-_single_and_halved.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg9\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m boxes \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\n\u001b[1;32m     13\u001b[0m box \u001b[38;5;241m=\u001b[39m boxes  \u001b[38;5;66;03m# returns one box\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:111\u001b[0m, in \u001b[0;36mYOLO.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:255\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m overrides \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m overrides:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mget_save_dir()\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:190\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:239\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch, profilers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, [], \u001b[38;5;28;01mNone\u001b[39;00m, (ops\u001b[38;5;241m.\u001b[39mProfile(), ops\u001b[38;5;241m.\u001b[39mProfile(), ops\u001b[38;5;241m.\u001b[39mProfile())\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_predict_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_predict_batch_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m batch\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/yolo/data/dataloaders/stream_loaders.py:224\u001b[0m, in \u001b[0;36mLoadImages.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m     im0 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage Not Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    225\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [path], [im0], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap, s\n","\u001b[0;31mFileNotFoundError\u001b[0m: Image Not Found /kaggle/working/data/Fichier:Avocado_Hass_-_single_and_halved.jpg"]}],"source":["img = '/kaggle/input/test2206/321_100.jpg'\n","#img2 = '/kaggle/working/data/Fruitsflow/dataset/val/images/6371.png'\n","img3 = '/kaggle/input/test2206/1.jpg' # OK 1 Apple Golden 3, 1 Pineapple Mini\n","img4 = '/kaggle/input/test2206/2.jpg'\n","img5 = '/kaggle/input/test2206/YOLOv8_multifruits1.jpg'\n","img6 = '/kaggle/input/test2206/legumes-plantravail.jpg'\n","img7 = '/kaggle/input/test2206/legumes-SANSplantravail.jpg'\n","img8 = 'https://www.youtube.com/watch?v=ASFWKTzIt_k'\n","img8 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/L%C3%A9gumes_pour_ratatouille_au_march%C3%A9_d%27Apt.jpg/2560px-L%C3%A9gumes_pour_ratatouille_au_march%C3%A9_d%27Apt.jpg\"\n","img9 = 'https://fr.wikipedia.org/wiki/Fichier:Avocado_Hass_-_single_and_halved.jpg'\n","results = model(img9)\n","boxes = results[0].boxes\n","box = boxes  # returns one box\n","box.xyxy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jB6DC0dIQLjt","trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","results.show()\n","#pandasbox=results.pandas().xyxy[0]\n","#print(pandasbox)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T05:54:27.269663Z","iopub.status.busy":"2023-06-25T05:54:27.268583Z","iopub.status.idle":"2023-06-25T05:54:30.270568Z","shell.execute_reply":"2023-06-25T05:54:30.269237Z","shell.execute_reply.started":"2023-06-25T05:54:27.269611Z"},"id":"37IQ8WPh20HR","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/runs/detect/train/ (stored 0%)\n","  adding: kaggle/working/runs/detect/train/PR_curve.png (deflated 22%)\n","  adding: kaggle/working/runs/detect/train/F1_curve.png (deflated 14%)\n","  adding: kaggle/working/runs/detect/train/val_batch1_labels.jpg (deflated 26%)\n","  adding: kaggle/working/runs/detect/train/train_batch0.jpg (deflated 20%)\n","  adding: kaggle/working/runs/detect/train/val_batch2_labels.jpg (deflated 28%)\n","  adding: kaggle/working/runs/detect/train/val_batch0_pred.jpg (deflated 28%)\n","  adding: kaggle/working/runs/detect/train/results.png (deflated 10%)\n","  adding: kaggle/working/runs/detect/train/args.yaml (deflated 51%)\n","  adding: kaggle/working/runs/detect/train/results.csv (deflated 85%)\n","  adding: kaggle/working/runs/detect/train/events.out.tfevents.1687657102.7887922fdec0.28.0 (deflated 74%)\n","  adding: kaggle/working/runs/detect/train/P_curve.png (deflated 19%)\n","  adding: kaggle/working/runs/detect/train/weights/ (stored 0%)\n","  adding: kaggle/working/runs/detect/train/weights/best.pt (deflated 37%)\n","  adding: kaggle/working/runs/detect/train/weights/best.onnx (deflated 37%)\n","  adding: kaggle/working/runs/detect/train/weights/last.pt (deflated 37%)\n","  adding: kaggle/working/runs/detect/train/confusion_matrix_normalized.png (deflated 27%)\n","  adding: kaggle/working/runs/detect/train/labels_correlogram.jpg (deflated 63%)\n","  adding: kaggle/working/runs/detect/train/val_batch1_pred.jpg (deflated 25%)\n","  adding: kaggle/working/runs/detect/train/val_batch2_pred.jpg (deflated 26%)\n","  adding: kaggle/working/runs/detect/train/val_batch0_labels.jpg (deflated 30%)\n","  adding: kaggle/working/runs/detect/train/R_curve.png (deflated 15%)\n","  adding: kaggle/working/runs/detect/train/train_batch1.jpg (deflated 19%)\n","  adding: kaggle/working/runs/detect/train/labels.jpg (deflated 39%)\n","  adding: kaggle/working/runs/detect/train/train_batch2.jpg (deflated 17%)\n","  adding: kaggle/working/runs/detect/train/confusion_matrix.png (deflated 26%)\n"]}],"source":["!zip -r /kaggle/working/220323train30epochsdataset3new3Scratch.zip /kaggle/working/runs/detect/train\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T06:31:32.259235Z","iopub.status.busy":"2023-06-25T06:31:32.258845Z","iopub.status.idle":"2023-06-25T06:31:32.267607Z","shell.execute_reply":"2023-06-25T06:31:32.265650Z","shell.execute_reply.started":"2023-06-25T06:31:32.259207Z"},"id":"8tf2Kzt-nyqm","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["UsageError: unrecognized arguments: as plt\n","WARNING ⚠️ Video stream unresponsive, please check your IP camera connection.\n","WARNING ⚠️ Video stream unresponsive, please check your IP camera connection.\n"]}],"source":["import numpy as np\n","#from matplotlib import pyplot as plt\n","%matplotlib inline as plt\n","\n","plt.imshow(np.squeeze(results.render()))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDufDAGsuQ-i","trusted":true},"outputs":[],"source":["!zip -r /kaggle/working/220322_Dataset2new_crops.zip /kaggle/working/runs/detect/predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytQxZpurnikE","trusted":true},"outputs":[],"source":["label_folder = '/kaggle/working/data/Fruitsflow/test/labels'\n","raw_images_folder = '/kaggle/working/data/Fruitsflow/test/labels'\n","save_images_folder = '/kaggle/working/save_images/'  \n","name_list_path = '/kaggle/working/data/Fruitsflow/data.yaml'  \n","classes_path = '/kaggle/working/data/Fruitsflow/data.yaml'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from PIL import Image, ImageDraw, ImageFont\n","\n","image_path = \"/kaggle/working/data/Fruitsflow/dataset/val/images/6371.png\"\n","\n","x = (0.37519290123456794*360)\n","y = (0.47241512345679015*360)\n","width = (0.1388888888888889*360)\n","height = (0.1388888888888889*360)\n","output_path = '/kaggle/working/result.png'\n","\n","def draw_box(image_path, x, y, width, height, output_path):\n","    # Open the image\n","    image = Image.open(image_path)\n","\n","    # Create a draw object\n","    draw = ImageDraw.Draw(image)\n","\n","    # Define the box coordinates\n","    upper_left = (x, y)\n","    lower_right = (x + width, y + height)\n","\n","    # Draw the box on the image\n","    draw.rectangle([upper_left, lower_right], outline='red', width=2)\n","\n","    # Save the modified image\n","    image.save(output_path)\n","    \n","draw_box(image_path, x, y, width, height, output_path)\n","im.show(output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["108 0.37519290123456794 0.47241512345679015 0.1388888888888889 0.1388888888888889\n","108 0.5974151234567902 0.5557484567901235 0.1388888888888889 0.1388888888888889\n","108 0.8529706790123457 0.6668595679012346 0.1388888888888889 0.1388888888888889\n","108 0.34463734567901233 0.7779706790123457 0.1388888888888889 0.1388888888888889\n","108 0.6918595679012346 0.8890817901234568 0.1388888888888889 0.1388888888888889\n","108 0.8474151234567902 1.0001929012345678 0.1388888888888889 0.1388888888888889\n","108 0.34463734567901233 0.6668595679012346 0.1388888888888889 0.1388888888888889\n","108 0.6918595679012346 0.5557484567901235 0.1388888888888889 0.1388888888888889\n","108 0.8474151234567902 0.47241512345679015 0.1388888888888889 0.1388888888888889\n","108 0.5974151234567902 0.47241512345679015 0.1388888888888889 0.1388888888888889\n","108 0.8474151234567902 0.5557484567901235 0.1388888888888889 0.1388888888888889\n","108 0.6918595679012346 0.6668595679012346 0.1388888888888889 0.1388888888888889"]},{"cell_type":"markdown","metadata":{},"source":["# @chakib : Intégration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T07:48:50.843901Z","iopub.status.busy":"2023-06-25T07:48:50.843514Z","iopub.status.idle":"2023-06-25T07:49:17.540396Z","shell.execute_reply":"2023-06-25T07:49:17.539449Z","shell.execute_reply.started":"2023-06-25T07:48:50.843874Z"},"trusted":true},"outputs":[],"source":["# Chargement du modèle\n","!pip install ultralytics\n","!pip install opencv-python\n","!pip install pillow"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T07:55:54.163485Z","iopub.status.busy":"2023-06-25T07:55:54.163139Z","iopub.status.idle":"2023-06-25T07:55:54.204816Z","shell.execute_reply":"2023-06-25T07:55:54.203806Z","shell.execute_reply.started":"2023-06-25T07:55:54.163463Z"},"trusted":true},"outputs":[],"source":["# Load le modèle\n","model = YOLO('/kaggle/input/besofl/best.pt')  # load a custom model"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T07:55:56.768974Z","iopub.status.busy":"2023-06-25T07:55:56.768599Z","iopub.status.idle":"2023-06-25T07:55:57.565648Z","shell.execute_reply":"2023-06-25T07:55:57.564451Z","shell.execute_reply.started":"2023-06-25T07:55:56.768936Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n","\n","\n","image 1/1 /kaggle/input/test2206/YOLOv8_multifruits2.jpg: 256x320 3 Apple Braeburns, 34.4ms\n","Speed: 1.0ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n","Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n"]}],"source":["results = model.predict('/kaggle/input/test2206/YOLOv8_multifruits2.jpg', save=True, imgsz=320, conf=0.3, show=True, save_conf=True, save_crop=True, boxes=True)"]},{"cell_type":"code","execution_count":179,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T08:10:11.243108Z","iopub.status.busy":"2023-06-25T08:10:11.242744Z","iopub.status.idle":"2023-06-25T08:10:11.251680Z","shell.execute_reply":"2023-06-25T08:10:11.250757Z","shell.execute_reply.started":"2023-06-25T08:10:11.243083Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[0, 0, 0]"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["# Display the annotated frame\n","#cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n","ingredients = []\n","\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bbox outputs\n","    for box in boxes:  # there could be more than one detection\n","        ingredients.append(int(box.cls))\n","            \n","ingredients"]},{"cell_type":"code","execution_count":121,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T07:50:15.917965Z","iopub.status.busy":"2023-06-25T07:50:15.917445Z","iopub.status.idle":"2023-06-25T07:50:16.226586Z","shell.execute_reply":"2023-06-25T07:50:16.224914Z","shell.execute_reply.started":"2023-06-25T07:50:15.917929Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n","fatal: destination path 'fruits360' already exists and is not an empty directory.\n"]}],"source":["%cd /kaggle/working/\n","! git clone https://github.com/971FLS/fruits360"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T08:05:15.994607Z","iopub.status.busy":"2023-06-25T08:05:15.994237Z","iopub.status.idle":"2023-06-25T08:05:16.009561Z","shell.execute_reply":"2023-06-25T08:05:16.007989Z","shell.execute_reply.started":"2023-06-25T08:05:15.994581Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>urls</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45</td>\n","      <td>/kaggle/working/fruits360/dataset/Training/App...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>98</td>\n","      <td>/kaggle/working/fruits360/dataset/Training/App...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>40</td>\n","      <td>/kaggle/working/fruits360/dataset/Training/App...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>85</td>\n","      <td>/kaggle/working/fruits360/dataset/Training/App...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>93</td>\n","      <td>/kaggle/working/fruits360/dataset/Training/App...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                                               urls\n","0     45  /kaggle/working/fruits360/dataset/Training/App...\n","1     98  /kaggle/working/fruits360/dataset/Training/App...\n","2     40  /kaggle/working/fruits360/dataset/Training/App...\n","3     85  /kaggle/working/fruits360/dataset/Training/App...\n","4     93  /kaggle/working/fruits360/dataset/Training/App..."]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["# Liste des répertoires\n","\n","import pandas as pd\n","import os\n","\n","df=[]\n","rootdir = '/kaggle/working/fruits360/dataset/Training'\n","for file in os.listdir(rootdir):\n","    d = os.path.join(rootdir, file)\n","    if os.path.isdir(d):\n","        df.append(d)\n","\n","df = pd.DataFrame(data=df, columns=['urls'])\n","df = df.sort_values(by='urls').reset_index()\n","df.head()"]},{"cell_type":"code","execution_count":169,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T08:07:20.563583Z","iopub.status.busy":"2023-06-25T08:07:20.563130Z","iopub.status.idle":"2023-06-25T08:07:20.574787Z","shell.execute_reply":"2023-06-25T08:07:20.572926Z","shell.execute_reply.started":"2023-06-25T08:07:20.563551Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0          Apple Braeburn\n","1      Apple Crimson Snow\n","2          Apple Golden 1\n","3          Apple Golden 2\n","4          Apple Golden 3\n","              ...        \n","126         Tomato Maroon\n","127         Tomato Yellow\n","128    Tomato not Ripened\n","129                Walnut\n","130            Watermelon\n","Name: classe, Length: 131, dtype: object"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["df['classe'] = df.urls.apply(lambda x: x.split('/')[-1])\n","df['classe']"]},{"cell_type":"code","execution_count":184,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T08:12:54.402226Z","iopub.status.busy":"2023-06-25T08:12:54.401852Z","iopub.status.idle":"2023-06-25T08:12:54.410269Z","shell.execute_reply":"2023-06-25T08:12:54.409253Z","shell.execute_reply.started":"2023-06-25T08:12:54.402199Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Apple Braeburn'"]},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["df['classe'][0]"]},{"cell_type":"code","execution_count":185,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T08:13:37.604411Z","iopub.status.busy":"2023-06-25T08:13:37.603981Z","iopub.status.idle":"2023-06-25T08:13:37.612364Z","shell.execute_reply":"2023-06-25T08:13:37.610881Z","shell.execute_reply.started":"2023-06-25T08:13:37.604380Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Apple Braeburn', 'Apple Braeburn', 'Apple Braeburn']"]},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["import pathlib\n","\n","#url = '/content/gdrive/MyDrive/Final/fruits360/dataset/Training'\n","url = '/kaggle/working/fruits360/dataset/Training'\n","\n","ingredients_liste = []\n","indexes = df.index\n","classes = df['classe']\n","\n","for ingredient in ingredients:\n","    ingredients_liste.append(df['classe'][0])\n","\n","ingredients_liste"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
